{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbe0806e",
   "metadata": {},
   "source": [
    "##### 1.Сделайте краткий обзор любой научной работы, посвящённой алгоритму для object detection, не рассматривавшемуся на уроке. Проведите анализ: чем отличается выбранная вами архитектура нейронной сети от других? В чём плюсы и минусы данной архитектуры? Какие могут возникнуть трудности при применении этой архитектуры на практике?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fbaf47",
   "metadata": {},
   "source": [
    "Архитектура Faster R-CNN объединяет Region Proposal Network (RPN) и Fast R-CNN в единую сеть\n",
    "путем совместного использования их свертывающих характеристик, используя недавно популярную\n",
    "терминологию нейронных сетей \"механизмы внимания\". RPN используется для генерации гипотез,\n",
    "получая на вход карту признаков изначального изображения. Сеть Faster R-CNN строится на одних и тех\n",
    "же весах с помощью следующего итеративного обучения:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0932056",
   "metadata": {},
   "source": [
    "1. Тренировка RPN сети. Свёрточные слои инициализируются весами, натренированными на\n",
    "ImageNet. Дообучаем на задаче определения регионов с каким-либо классом (уточнением\n",
    "класса занимается часть Fast R-CNN).\n",
    "2. Тренировка Fast R-CNN сети. Свёрточные слои инициализируются весами, натренированными\n",
    "на ImageNet. Дообучаем, используя гипотезы об объектах с помощью RPN сети, обученной в п.1.\n",
    "В этот раз задачей обучения является уточнение координат и определение конкретного класса\n",
    "объекта.\n",
    "После выполнения п.2 мы имеем две нейронных сети с разными весами для свёрточных слоёв.\n",
    "3. Обучаем только RPN часть, используя веса из п.2 (слои, идущие до RPN сети, принадлежащие\n",
    "feature extractor, замораживаются и никак не изменяются).\n",
    "4. Обучаем слои для Fast R-CNN, используя веса из п.3 (то есть, уже более точно настроенный RPN),\n",
    "(остальные веса – идущие ранее или относящиеся к RPN — заморожены).\n",
    "Таким образом, архитектура Faster R-CNN отличается от других архитектур тем, что генерация\n",
    "гипотез выполняется с помощью отдельно дифференцируемого модуля и в архитектуре реализовано\n",
    "итеративное обучение.\n",
    "Преимуществом архитектуры Faster R-CNN являются быстрота и точность. Архитектура Faster RCNN справляется немного хуже с локализацией. RPN может быть трудно работать с объектами разных\n",
    "масштабов. RPN имеет фиксированное приемное поле. Таким образом, малые объекты могут занимать\n",
    "очень небольшую часть рецептивного поля или, если объекты очень большие, то рецептивное поле\n",
    "будет содержать только часть объекта. Проблему можно решать, тренируя множество RPN для\n",
    "различных масштабов: каждая часть RPN будет принимать различные свёрточные слои или наборы\n",
    "слоёв в качестве входа, так что приемное поле будет разного размера. Это значительно улучшит\n",
    "одновременное обнаружение малых и крупных объектов моделью Faster R-CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d054ca",
   "metadata": {},
   "source": [
    "#### Особенности тренировки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd606af",
   "metadata": {},
   "source": [
    "Фактически необходимо натренировать две сети: Fast R-CNN для классификации и уточнения координат объектов, RPN для генерации претендентов. При этом свёрточные слои должны быть общими для этих двух сетей (собственно, всё и затевалось ради того, чтобы суметь использовать одну карту особенностей для решения обеих задач).\n",
    "\n",
    "Авторы предлагают несколько возможных подходов к тренировке, однако, результаты, представленные в статье, получены при помощи тренировки по следующей схеме:\n",
    "\n",
    " 1. Тренируем сеть для генерации претендентов. Для этого инициализируем свёрточные слои весами натренированными на ImageNet и доуточняем веса свёрточных слоёв и слоёв RPN части \n",
    " \n",
    " 2. Тренируем сеть Fast R-CNN сеть. Свёрточные слои инициализируем весами от сети, натренированной на ImageNet и дотренировываем. При этом претенденты для изображения генерируем при помощи сети полученной в п.1.\n",
    "\n",
    " 3. Важно, что после выполнения п.2 мы имеем две нейронных сети с разными весами для свёрточных слоёв.\n",
    "\n",
    " 4. Берем свёрточные слои от Fast R-CNN, которую натренировали в п.2, переносим их в RPN сеть и дотренировываем её. При этом веса свёрточных слоёв фиксируются, а тренируются только веса слоёв rpn_conv, rpn_cls_score и rpn_bbox_pred.\n",
    "\n",
    "5. Дотренировываем Fast R-CNN с учетом изменившегося генератора претендентов. При этом опять не меняем веса свёрточных слоёв, и тренируем только слои специфичные для Fast R-CNN.\n",
    "\n",
    "На этом тренировка заканчивается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bc03d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcJKO5sKEMeA"
      },
      "source": [
        "## Урок 5. Рекуррентные нейронные сети\n",
        "## Практическое задание\n",
        "\n",
        "<ol>\n",
        "    <li>Попробуйте изменить параметры нейронной сети, работающей с датасетом imdb, либо нейронной сети, работающей с airline-passengers (она прилагается вместе с датасетом к уроку в виде отдельного скрипта), так, чтобы улучшить ее точность. Приложите анализ.</li>\n",
        "    <li>Попробуйте изменить параметры нейронной сети, генерирующей текст, таким образом, чтобы добиться генерации как можно более осмысленного текста. Пришлите лучший получившийся у вас текст и опишите то, что вы предприняли, чтобы его получить. Можно использовать текст другого прозведения.</li>\n",
        "    <li>* Попробуйте на numpy реализовать нейронную сеть архитектуры. LSTM</li>\n",
        "    <li>* Предложите свои варианты решения проблемы исчезающего градиента в RNN.</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель 1"
      ],
      "metadata": {
        "id": "TnjYw6BG36SQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vyPcVErxgwAu",
        "outputId": "1d053f9d-ffc2-4075-d5ae-25d35256e704",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Построение модели...\n",
            "Загрузка данных...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n",
            "25000 тренировочные последовательности\n",
            "25000 тестовые последовательности\n",
            "Pad последовательности (примеров в x единицу времени)\n",
            "x_train shape: (25000, 100)\n",
            "x_test shape: (25000, 100)\n",
            "Процесс обучения...\n",
            "Epoch 1/10\n",
            "196/196 [==============================] - 122s 569ms/step - loss: 0.4540 - accuracy: 0.7720 - val_loss: 0.4506 - val_accuracy: 0.8254\n",
            "Epoch 2/10\n",
            "196/196 [==============================] - 100s 509ms/step - loss: 0.2868 - accuracy: 0.8838 - val_loss: 0.3378 - val_accuracy: 0.8515\n",
            "Epoch 3/10\n",
            "196/196 [==============================] - 102s 522ms/step - loss: 0.2180 - accuracy: 0.9136 - val_loss: 0.3562 - val_accuracy: 0.8457\n",
            "Epoch 4/10\n",
            "196/196 [==============================] - 98s 500ms/step - loss: 0.1800 - accuracy: 0.9319 - val_loss: 0.4746 - val_accuracy: 0.8362\n",
            "Epoch 5/10\n",
            "196/196 [==============================] - 97s 496ms/step - loss: 0.1391 - accuracy: 0.9480 - val_loss: 0.4398 - val_accuracy: 0.8326\n",
            "Epoch 6/10\n",
            "196/196 [==============================] - 96s 491ms/step - loss: 0.1176 - accuracy: 0.9563 - val_loss: 0.5801 - val_accuracy: 0.8269\n",
            "Epoch 7/10\n",
            "196/196 [==============================] - 102s 524ms/step - loss: 0.0970 - accuracy: 0.9629 - val_loss: 0.5877 - val_accuracy: 0.8262\n",
            "Epoch 8/10\n",
            "196/196 [==============================] - 95s 486ms/step - loss: 0.0829 - accuracy: 0.9695 - val_loss: 0.6382 - val_accuracy: 0.8278\n",
            "Epoch 9/10\n",
            "196/196 [==============================] - 94s 478ms/step - loss: 0.0712 - accuracy: 0.9750 - val_loss: 0.7684 - val_accuracy: 0.8248\n",
            "Epoch 10/10\n",
            "196/196 [==============================] - 96s 486ms/step - loss: 0.0594 - accuracy: 0.9797 - val_loss: 0.7784 - val_accuracy: 0.8206\n",
            "196/196 [==============================] - 7s 34ms/step - loss: 0.7784 - accuracy: 0.8206\n",
            "Результат при тестировании: 0.7784128189086914\n",
            "Тестовая точность: 0.8206400275230408\n",
            "CPU times: user 21min 22s, sys: 2min 8s, total: 23min 31s\n",
            "Wall time: 16min 55s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "max_features = 10000\n",
        "\n",
        "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
        "maxlen = 100\n",
        "batch_size = 128 # увеличьте значение для ускорения обучения\n",
        "def train_nn():\n",
        "  print('Построение модели...')\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(max_features, 128))\n",
        "  model.add(LSTM(128, dropout=0.4, recurrent_dropout=0.4, implementation=2))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  print('Загрузка данных...')\n",
        " #стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer='Adam', # при использовании этого оптимайзера модель показывает наилучшие результаты.\n",
        "                metrics=['accuracy'])\n",
        "  (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "  print(len(x_train), 'тренировочные последовательности')\n",
        "  print(len(x_test), 'тестовые последовательности')\n",
        "\n",
        "  print('Pad последовательности (примеров в x единицу времени)')\n",
        "  x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "  x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "  print('x_train shape:', x_train.shape)\n",
        "  print('x_test shape:', x_test.shape)\n",
        "\n",
        "  print('Процесс обучения...')\n",
        "  model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=10, # увеличьте при необходимости\n",
        "            validation_data=(x_test, y_test))\n",
        "  score, acc = model.evaluate(x_test, y_test,\n",
        "                              batch_size=batch_size)\n",
        "  print('Результат при тестировании:', score)\n",
        "  print('Тестовая точность:', acc)\n",
        "\n",
        "\n",
        "\n",
        "train_nn()\n",
        "  #"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "maxlen = 128\n",
        "from keras.layers import Dropout"
      ],
      "metadata": {
        "id": "vIGXm9PGDZ3n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель 2"
      ],
      "metadata": {
        "id": "TEmuH68W4V9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "batch_size = 64\n",
        "epochs = 30\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras.utils import pad_sequences\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.4, recurrent_dropout=0.4))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32, activation='LeakyReLU'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(16, activation='elu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Use a different optimizer\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='RMSprop',\n",
        "              metrics=['accuracy'])\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "# Train the model\n",
        "model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "id": "GPeBDkufab_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e63a7917-e2e4-4e31-eae6-03478b0969a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "391/391 [==============================] - 255s 638ms/step - loss: 0.5322 - accuracy: 0.7290 - val_loss: 0.3626 - val_accuracy: 0.8394\n",
            "Epoch 2/30\n",
            "391/391 [==============================] - 248s 636ms/step - loss: 0.3613 - accuracy: 0.8560 - val_loss: 0.3376 - val_accuracy: 0.8576\n",
            "Epoch 3/30\n",
            "391/391 [==============================] - 251s 642ms/step - loss: 0.3058 - accuracy: 0.8828 - val_loss: 0.3637 - val_accuracy: 0.8405\n",
            "Epoch 4/30\n",
            "391/391 [==============================] - 260s 666ms/step - loss: 0.2741 - accuracy: 0.8977 - val_loss: 0.3164 - val_accuracy: 0.8626\n",
            "Epoch 5/30\n",
            "391/391 [==============================] - 253s 645ms/step - loss: 0.2462 - accuracy: 0.9064 - val_loss: 0.3249 - val_accuracy: 0.8649\n",
            "Epoch 6/30\n",
            "391/391 [==============================] - 240s 614ms/step - loss: 0.2241 - accuracy: 0.9175 - val_loss: 0.3454 - val_accuracy: 0.8510\n",
            "Epoch 7/30\n",
            "391/391 [==============================] - 243s 621ms/step - loss: 0.1977 - accuracy: 0.9289 - val_loss: 0.3834 - val_accuracy: 0.8602\n",
            "Epoch 8/30\n",
            "391/391 [==============================] - 242s 620ms/step - loss: 0.1838 - accuracy: 0.9341 - val_loss: 0.3698 - val_accuracy: 0.8579\n",
            "Epoch 9/30\n",
            "391/391 [==============================] - 242s 619ms/step - loss: 0.1659 - accuracy: 0.9432 - val_loss: 0.4942 - val_accuracy: 0.8428\n",
            "Epoch 10/30\n",
            "391/391 [==============================] - 245s 627ms/step - loss: 0.1515 - accuracy: 0.9481 - val_loss: 0.4211 - val_accuracy: 0.8594\n",
            "Epoch 11/30\n",
            "391/391 [==============================] - 246s 630ms/step - loss: 0.1351 - accuracy: 0.9539 - val_loss: 0.5340 - val_accuracy: 0.8340\n",
            "Epoch 12/30\n",
            "391/391 [==============================] - 237s 607ms/step - loss: 0.1225 - accuracy: 0.9599 - val_loss: 0.4376 - val_accuracy: 0.8556\n",
            "Epoch 13/30\n",
            "391/391 [==============================] - 238s 608ms/step - loss: 0.1091 - accuracy: 0.9632 - val_loss: 0.4671 - val_accuracy: 0.8530\n",
            "Epoch 14/30\n",
            "391/391 [==============================] - 247s 632ms/step - loss: 0.0945 - accuracy: 0.9690 - val_loss: 0.5363 - val_accuracy: 0.8468\n",
            "Epoch 15/30\n",
            "391/391 [==============================] - 247s 632ms/step - loss: 0.0890 - accuracy: 0.9712 - val_loss: 0.6242 - val_accuracy: 0.8431\n",
            "Epoch 16/30\n",
            "391/391 [==============================] - 246s 630ms/step - loss: 0.0779 - accuracy: 0.9745 - val_loss: 0.7697 - val_accuracy: 0.8131\n",
            "Epoch 17/30\n",
            "391/391 [==============================] - 238s 609ms/step - loss: 0.0736 - accuracy: 0.9764 - val_loss: 0.7369 - val_accuracy: 0.8529\n",
            "Epoch 18/30\n",
            "391/391 [==============================] - 248s 634ms/step - loss: 0.0675 - accuracy: 0.9782 - val_loss: 0.7185 - val_accuracy: 0.8492\n",
            "Epoch 19/30\n",
            "391/391 [==============================] - 241s 614ms/step - loss: 0.0572 - accuracy: 0.9826 - val_loss: 0.6455 - val_accuracy: 0.8432\n",
            "Epoch 20/30\n",
            "391/391 [==============================] - 244s 625ms/step - loss: 0.0525 - accuracy: 0.9825 - val_loss: 0.7457 - val_accuracy: 0.8472\n",
            "Epoch 21/30\n",
            "391/391 [==============================] - 236s 604ms/step - loss: 0.0470 - accuracy: 0.9860 - val_loss: 0.8439 - val_accuracy: 0.8504\n",
            "Epoch 22/30\n",
            "391/391 [==============================] - 244s 625ms/step - loss: 0.0448 - accuracy: 0.9871 - val_loss: 0.8525 - val_accuracy: 0.8517\n",
            "Epoch 23/30\n",
            "391/391 [==============================] - 239s 611ms/step - loss: 0.0427 - accuracy: 0.9870 - val_loss: 0.8211 - val_accuracy: 0.8494\n",
            "Epoch 24/30\n",
            "391/391 [==============================] - 244s 625ms/step - loss: 0.0412 - accuracy: 0.9872 - val_loss: 0.8813 - val_accuracy: 0.8492\n",
            "Epoch 25/30\n",
            "391/391 [==============================] - 239s 611ms/step - loss: 0.0395 - accuracy: 0.9878 - val_loss: 0.9065 - val_accuracy: 0.8491\n",
            "Epoch 26/30\n",
            "391/391 [==============================] - 240s 614ms/step - loss: 0.0315 - accuracy: 0.9904 - val_loss: 1.2434 - val_accuracy: 0.8111\n",
            "Epoch 27/30\n",
            "391/391 [==============================] - 244s 624ms/step - loss: 0.0343 - accuracy: 0.9895 - val_loss: 0.8704 - val_accuracy: 0.8475\n",
            "Epoch 28/30\n",
            "391/391 [==============================] - 246s 629ms/step - loss: 0.0310 - accuracy: 0.9913 - val_loss: 0.9773 - val_accuracy: 0.8503\n",
            "Epoch 29/30\n",
            "391/391 [==============================] - 275s 703ms/step - loss: 0.0296 - accuracy: 0.9919 - val_loss: 1.0304 - val_accuracy: 0.8479\n",
            "Epoch 30/30\n",
            "391/391 [==============================] - 278s 710ms/step - loss: 0.0266 - accuracy: 0.9928 - val_loss: 1.1174 - val_accuracy: 0.8450\n",
            "CPU times: user 2h 36min 58s, sys: 16min 3s, total: 2h 53min 2s\n",
            "Wall time: 2h 3min 31s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78dfacc7dc30>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель 3"
      ],
      "metadata": {
        "id": "aAn9thkJ4mNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from keras.backend import dropout\n",
        "def train_nn_1():\n",
        "  print('Загрузка данных...')\n",
        "  (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "  print(len(x_train), 'тренировочные последовательности')\n",
        "  print(len(x_test), 'тестовые последовательности')\n",
        "\n",
        "  print('Pad последовательности (примеров в x единицу времени)')\n",
        "  x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "  x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "  print('x_train shape:', x_train.shape)\n",
        "  print('x_test shape:', x_test.shape)\n",
        "\n",
        "  print('Построение модели...')\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(max_features, 128))\n",
        "  model.add(LSTM(128, dropout=0.4, recurrent_dropout=0.4))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(32, activation='LeakyReLU'))            # New line\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(16, activation='elu'))\n",
        "  model.add(Dropout(0.2))                                  # New line\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer='RMSprop', # при использовании этого оптимайзера модель показывает наилучшие результаты.\n",
        "                metrics=['accuracy'])\n",
        "  callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
        "  print('Процесс обучения...')\n",
        "  model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=10, # увеличьте при необходимости\n",
        "            callbacks = callbacks,\n",
        "            validation_data=(x_test, y_test))\n",
        "  score, acc = model.evaluate(x_test, y_test,\n",
        "                              batch_size=batch_size)\n",
        "  print('Результат при тестировании:', score)\n",
        "  print('Тестовая точность:', acc)\n",
        "train_nn_1()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWHzc_8DCpe9",
        "outputId": "2e85aa39-e71f-461b-ca18-54c59f03ed4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загрузка данных...\n",
            "25000 тренировочные последовательности\n",
            "25000 тестовые последовательности\n",
            "Pad последовательности (примеров в x единицу времени)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (25000, 128)\n",
            "x_test shape: (25000, 128)\n",
            "Построение модели...\n",
            "Процесс обучения...\n",
            "Epoch 1/10\n",
            "98/98 [==============================] - 71s 681ms/step - loss: 0.6563 - accuracy: 0.6050 - val_loss: 0.6003 - val_accuracy: 0.6570\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 67s 689ms/step - loss: 0.4686 - accuracy: 0.7908 - val_loss: 0.4005 - val_accuracy: 0.8260\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 65s 666ms/step - loss: 0.3833 - accuracy: 0.8430 - val_loss: 0.3837 - val_accuracy: 0.8297\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 66s 677ms/step - loss: 0.3377 - accuracy: 0.8662 - val_loss: 0.3501 - val_accuracy: 0.8455\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 64s 652ms/step - loss: 0.3048 - accuracy: 0.8845 - val_loss: 0.3416 - val_accuracy: 0.8534\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 62s 633ms/step - loss: 0.2832 - accuracy: 0.8914 - val_loss: 0.3803 - val_accuracy: 0.8324\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 66s 670ms/step - loss: 0.2617 - accuracy: 0.9030 - val_loss: 0.3465 - val_accuracy: 0.8634\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 64s 650ms/step - loss: 0.2399 - accuracy: 0.9121 - val_loss: 0.3527 - val_accuracy: 0.8612\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 64s 651ms/step - loss: 0.2263 - accuracy: 0.9164 - val_loss: 0.4987 - val_accuracy: 0.8223\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 64s 657ms/step - loss: 0.2171 - accuracy: 0.9218 - val_loss: 0.3680 - val_accuracy: 0.8590\n",
            "98/98 [==============================] - 4s 36ms/step - loss: 0.3680 - accuracy: 0.8590\n",
            "Результат при тестировании: 0.3680456280708313\n",
            "Тестовая точность: 0.859000027179718\n",
            "CPU times: user 13min 55s, sys: 1min 21s, total: 15min 16s\n",
            "Wall time: 11min 2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для решения данной задачи лучше себя показала модель № 3 , Существенное увеличение эпох и уменьшение скорости обучения не существенно улучшает модель"
      ],
      "metadata": {
        "id": "nPYdJhHgmvhi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CwkhewmMsO-_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}